{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "446258e5-7cf2-4a73-8dd7-7b7a43fdd98e",
        "outputId": "9d8ba48c-7e45-40d8-9fb5-39615e273860"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.8)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch numpy pandas matplotlib"
      ],
      "id": "446258e5-7cf2-4a73-8dd7-7b7a43fdd98e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ex0UM97ZMR_l"
      },
      "source": [
        "# Data preprocessing\n",
        "\n",
        "load file from google drive before you run this"
      ],
      "id": "Ex0UM97ZMR_l"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NIA_NKQMRw8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9952f09-b03f-4a10-ec2e-9a99fedf9c80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  return func(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "column_name: movie_id max: 3952 min: 1\n",
            "unique values:  3883\n",
            "column_name: title max: eXistenZ (1999) min: $1,000,000 Duck (1971)\n",
            "unique values:  3883\n",
            "column_name: genres max: 300 min: 0\n",
            "unique values:  301\n",
            "column_name: user_id max: 6040 min: 1\n",
            "unique values:  6040\n",
            "column_name: movie_id max: 3952 min: 1\n",
            "unique values:  3706\n",
            "column_name: rating max: 5.0 min: 1.0\n",
            "unique values:  5\n",
            "column_name: unix_timestamp max: 1046454590 min: 956703932\n",
            "unique values:  458455\n",
            "column_name: user_id max: 6040 min: 1\n",
            "unique values:  6040\n",
            "column_name: sex max: 1 min: 0\n",
            "unique values:  2\n",
            "column_name: age_group max: 56 min: 1\n",
            "unique values:  7\n",
            "column_name: occupation max: 20 min: 0\n",
            "unique values:  21\n",
            "column_name: zip_code max: 99945 min: 00231\n",
            "unique values:  3439\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.utils.data\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "import os\n",
        "def get_index_range(df, column_name):\n",
        "    print(\"column_name: {} max: {} min: {}\".format(column_name, df[column_name].max(), df[column_name].min()))\n",
        "    print(\"unique values: \", df[column_name].nunique())\n",
        "\n",
        "def get_dataset_info(df):\n",
        "    for column_name in df.columns:\n",
        "        get_index_range(df, column_name)\n",
        "\n",
        "\n",
        "if not os.path.exists(\"train_data.csv\") or not os.path.exists(\"test_data.csv\"):\n",
        "    users = pd.read_csv(\n",
        "        \"users.dat\",\n",
        "        sep=\"::\",\n",
        "        names=[\"user_id\", \"sex\", \"age_group\", \"occupation\", \"zip_code\"],\n",
        "    )\n",
        "\n",
        "    ratings = pd.read_csv(\n",
        "        \"ratings.dat\",\n",
        "        sep=\"::\",\n",
        "        names=[\"user_id\", \"movie_id\", \"rating\", \"unix_timestamp\"],\n",
        "    )\n",
        "\n",
        "    movies = pd.read_csv(\n",
        "        \"movies.dat\", sep=\"::\", names=[\"movie_id\", \"title\", \"genres\"], encoding='latin-1'\n",
        "    )\n",
        "    # if you want occupation as text\n",
        "    occupation = {0: \"other\", 1: \"academic/educator\", 2: \"artist\", 3: \"clerical/admin\", 4: \"college/grad student\",\n",
        "                  5: \"customer service\", 6: \"doctor/health care\", 7: \"executive/managerial\", 8: \"farmer\", 9: \"homemaker\",\n",
        "                  10: \"K-12 student\", 11: \"lawyer\", 12: \"programmer\", 13: \"retired\", 14: \"sales/marketing\", 15: \"scientist\",\n",
        "                  16: \"self-employed\", 17: \"technician/engineer\", 18: \"tradesman/craftsman\", 19: \"unemployed\", 20: \"writer\"}\n",
        "    sex_dict = {'F': 0, 'M': 1}\n",
        "\n",
        "    users[\"user_id\"] = users[\"user_id\"].apply(lambda x: int(x))\n",
        "    users[\"age_group\"] = users[\"age_group\"].apply(lambda x: int(x))\n",
        "    # if you want occupation as text\n",
        "    # users[\"occupation\"] = users[\"occupation\"].apply(lambda x: occupation[int(x)])\n",
        "    users[\"occupation\"] = users[\"occupation\"].apply(lambda x: int(x))\n",
        "    users[\"sex\"] = users[\"sex\"].apply(lambda x: sex_dict[x])\n",
        "\n",
        "    movies[\"movie_id\"] = movies[\"movie_id\"].apply(lambda x: int(x))\n",
        "\n",
        "    ratings[\"movie_id\"] = ratings[\"movie_id\"].apply(lambda x: int(x))\n",
        "    ratings[\"user_id\"] = ratings[\"user_id\"].apply(lambda x: int(x))\n",
        "    ratings[\"rating\"] = ratings[\"rating\"].apply(lambda x: float(x))\n",
        "\n",
        "    genres = [\n",
        "        \"Action\",\n",
        "        \"Adventure\",\n",
        "        \"Animation\",\n",
        "        \"Children's\",\n",
        "        \"Comedy\",\n",
        "        \"Crime\",\n",
        "        \"Documentary\",\n",
        "        \"Drama\",\n",
        "        \"Fantasy\",\n",
        "        \"Film-Noir\",\n",
        "        \"Horror\",\n",
        "        \"Musical\",\n",
        "        \"Mystery\",\n",
        "        \"Romance\",\n",
        "        \"Sci-Fi\",\n",
        "        \"Thriller\",\n",
        "        \"War\",\n",
        "        \"Western\",\n",
        "    ]\n",
        "\n",
        "    genre_ids = {genre: i for genre, i in zip(genres, range(len(genres)))}\n",
        "    genre_comb_map = {}\n",
        "\n",
        "    def genre_to_index(genre_str):\n",
        "        genre_lst = genre_str.split(\"|\")\n",
        "        value = 0\n",
        "        for g in genre_lst:\n",
        "            value |= (1 << genre_ids[g])\n",
        "        if value not in genre_comb_map:\n",
        "            genre_comb_map[value] = len(genre_comb_map)\n",
        "        return genre_comb_map[value]\n",
        "\n",
        "    movies.genres = movies.genres.apply(lambda x: genre_to_index(x))\n",
        "\n",
        "    # Print dataset info after transformations\n",
        "    get_dataset_info(movies)\n",
        "    get_dataset_info(ratings)\n",
        "    get_dataset_info(users)\n",
        "\n",
        "    ratings = ratings.join(movies.set_index(\"movie_id\"), on=\"movie_id\")\n",
        "    ratings_group = ratings.sort_values(by=[\"unix_timestamp\"]).groupby(\"user_id\")\n",
        "\n",
        "    ratings_data = pd.DataFrame(\n",
        "        data={\n",
        "            \"user_id\": list(ratings_group.groups.keys()),\n",
        "            \"movie_ids\": list(ratings_group.movie_id.apply(list)),\n",
        "            \"ratings\": list(ratings_group.rating.apply(list)),\n",
        "            \"genres\": list(ratings_group.genres.apply(list)),\n",
        "            \"timestamps\": list(ratings_group.unix_timestamp.apply(list)),\n",
        "        }\n",
        "    )\n",
        "\n",
        "    sequence_length = 10\n",
        "    step_size = 2\n",
        "\n",
        "\n",
        "    def create_sequences(values, window_size, step_size):\n",
        "        sequences = []\n",
        "        start_index = 0\n",
        "        while True:\n",
        "            end_index = start_index + window_size\n",
        "            seq = values[start_index:end_index]\n",
        "            if len(seq) < window_size:\n",
        "                seq = values[-window_size:]\n",
        "                if len(seq) == window_size:\n",
        "                    sequences.append(seq)\n",
        "                break\n",
        "            sequences.append(seq)\n",
        "            start_index += step_size\n",
        "        return sequences\n",
        "\n",
        "    ratings_data.movie_ids = ratings_data.movie_ids.apply(\n",
        "        lambda ids: create_sequences(ids, sequence_length, step_size)\n",
        "    )\n",
        "\n",
        "    ratings_data.ratings = ratings_data.ratings.apply(\n",
        "        lambda ids: create_sequences(ids, sequence_length, step_size)\n",
        "    )\n",
        "\n",
        "    ratings_data.genres = ratings_data.genres.apply(\n",
        "        lambda ids: create_sequences(ids, sequence_length, step_size)\n",
        "    )\n",
        "\n",
        "    del ratings_data[\"timestamps\"]\n",
        "\n",
        "    ratings_data_movies = ratings_data[[\"user_id\", \"movie_ids\"]].explode(\n",
        "        \"movie_ids\", ignore_index=True\n",
        "    )\n",
        "    ratings_data_rating = ratings_data[[\"ratings\"]].explode(\"ratings\", ignore_index=True)\n",
        "    ratings_data_genres = ratings_data[[\"genres\"]].explode(\"genres\", ignore_index=True)\n",
        "    ratings_data_transformed = pd.concat([ratings_data_movies, ratings_data_rating, ratings_data_genres], axis=1)\n",
        "    ratings_data_transformed = ratings_data_transformed.join(\n",
        "        users.set_index(\"user_id\"), on=\"user_id\"\n",
        "    )\n",
        "\n",
        "    ratings_data_transformed.movie_ids = ratings_data_transformed.movie_ids.apply(\n",
        "        lambda x: \",\".join([str(v) for v in x])\n",
        "    )\n",
        "    ratings_data_transformed.ratings = ratings_data_transformed.ratings.apply(\n",
        "        lambda x: \",\".join([str(v) for v in x])\n",
        "    )\n",
        "    ratings_data_transformed.genres = ratings_data_transformed.genres.apply(\n",
        "        lambda x: \",\".join([str(v) for v in x])\n",
        "    )\n",
        "\n",
        "    del ratings_data_transformed[\"zip_code\"]\n",
        "\n",
        "    ratings_data_transformed.rename(\n",
        "        columns={\"movie_ids\": \"sequence_movie_ids\", \"ratings\": \"sequence_ratings\"},\n",
        "        inplace=True,\n",
        "    )\n",
        "\n",
        "    random_selection = np.random.rand(len(ratings_data_transformed.index)) <= 0.85\n",
        "    train_data = ratings_data_transformed[random_selection]\n",
        "    test_data = ratings_data_transformed[~random_selection]\n",
        "\n",
        "    train_data.to_csv(\"train_data.csv\", index=False, sep=\"|\", header=False)\n",
        "    test_data.to_csv(\"test_data.csv\", index=False, sep=\"|\", header=False)\n",
        "    ratings_data_transformed.to_csv(\"all_data.csv\", index=False, sep=\"|\", header=False)\n"
      ],
      "id": "1NIA_NKQMRw8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pR4r_27nOJ_Z"
      },
      "source": [
        "# Dataset & Dataloader"
      ],
      "id": "pR4r_27nOJ_Z"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_iSX83vNOKdl"
      },
      "outputs": [],
      "source": [
        "class MovieLensDataset(Dataset):\n",
        "    def __init__(self, file_name):\n",
        "        self.df = pd.read_csv(file_name, delimiter='|')\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def expand_to_list(self, value, seq_len):\n",
        "        return np.array([int(value)] * seq_len)\n",
        "\n",
        "    def __getitem__(self, idx, is_training=True):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        movies = self.df.iloc[idx, 1].split(',')\n",
        "        ratings = self.df.iloc[idx, 2].split(',')\n",
        "        genres = self.df.iloc[idx, 3].split(',')\n",
        "        seq_len = len(movies)\n",
        "        ret = {\n",
        "            'user_id': self.expand_to_list(self.df.iloc[idx, 0], seq_len),\n",
        "            'movie_id': np.array(movies).astype(int),\n",
        "            'rating': np.array(ratings).astype(float),\n",
        "            'genres':np.array(genres).astype(int),\n",
        "            'sex': self.expand_to_list(self.df.iloc[idx, 4], seq_len),\n",
        "            'age': self.expand_to_list(self.df.iloc[idx, 5], seq_len),\n",
        "            'occupation': self.expand_to_list(self.df.iloc[idx, 6], seq_len),\n",
        "        }\n",
        "        return ret\n",
        "\n",
        "test_dataset = MovieLensDataset('test_data.csv')\n",
        "train_dataset = MovieLensDataset('train_data.csv')"
      ],
      "id": "_iSX83vNOKdl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yc4-R7_gNTNF",
        "outputId": "2a35c2ce-cedc-4a07-d2b3-0de448b07e17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 {'user_id': tensor([[1607, 1607, 1607, 1607, 1607, 1607, 1607, 1607, 1607, 1607],\n",
            "        [1243, 1243, 1243, 1243, 1243, 1243, 1243, 1243, 1243, 1243],\n",
            "        [1140, 1140, 1140, 1140, 1140, 1140, 1140, 1140, 1140, 1140],\n",
            "        [3558, 3558, 3558, 3558, 3558, 3558, 3558, 3558, 3558, 3558],\n",
            "        [1340, 1340, 1340, 1340, 1340, 1340, 1340, 1340, 1340, 1340],\n",
            "        [4746, 4746, 4746, 4746, 4746, 4746, 4746, 4746, 4746, 4746],\n",
            "        [ 608,  608,  608,  608,  608,  608,  608,  608,  608,  608],\n",
            "        [1790, 1790, 1790, 1790, 1790, 1790, 1790, 1790, 1790, 1790],\n",
            "        [ 509,  509,  509,  509,  509,  509,  509,  509,  509,  509],\n",
            "        [2383, 2383, 2383, 2383, 2383, 2383, 2383, 2383, 2383, 2383]]), 'movie_id': tensor([[1365, 2248, 2067, 2791,  594,  523,  978, 2437, 2345, 3949],\n",
            "        [ 597, 2003, 2144, 1380, 3712, 2145, 2746, 2150, 1297, 1441],\n",
            "        [2905, 1304,   36,  318, 2366, 1465, 2700, 3653, 2202, 1957],\n",
            "        [ 539,  344, 2372, 2416,  788, 3688, 1895,  520, 1135, 1377],\n",
            "        [ 647, 2734, 1061, 2747,  724, 3263, 1093, 2247, 2706, 3142],\n",
            "        [ 908,  435,  593,  534, 2433, 3578, 3753, 3752, 3624, 2028],\n",
            "        [  69, 1909, 3263,  175, 1396,  344,  367, 2506, 2793, 3146],\n",
            "        [3873, 2111,  628, 2599, 1090, 2116, 2333, 3114,  593, 1272],\n",
            "        [  48,  550,  168, 2316, 2154, 1100, 2558,  237, 3705,  427],\n",
            "        [2137,  661, 1566, 3653,  750,  541,  968, 1240,  589, 2455]]), 'rating': tensor([[4., 2., 3., 2., 4., 1., 2., 4., 3., 4.],\n",
            "        [4., 3., 3., 3., 3., 3., 2., 4., 4., 4.],\n",
            "        [5., 4., 5., 3., 5., 4., 4., 3., 3., 3.],\n",
            "        [5., 5., 5., 5., 5., 5., 3., 5., 4., 3.],\n",
            "        [1., 4., 1., 1., 1., 3., 1., 1., 3., 1.],\n",
            "        [3., 3., 3., 5., 4., 5., 5., 1., 4., 5.],\n",
            "        [1., 2., 1., 2., 2., 5., 1., 2., 3., 3.],\n",
            "        [1., 4., 4., 2., 5., 1., 1., 4., 5., 5.],\n",
            "        [1., 2., 2., 2., 3., 2., 3., 2., 2., 4.],\n",
            "        [4., 4., 4., 3., 4., 4., 1., 4., 4., 3.]], dtype=torch.float64), 'genres': tensor([[ 12,   9,  45,   4,  83,  12,  12,  12,  12,  12],\n",
            "        [  2,  10,   4, 139,   4,   9, 269,   4,   4,   2],\n",
            "        [ 27,  85,  12,  12, 248,  12, 164,  24,  50,  12],\n",
            "        [  2,   4,   4,   4, 131,   4,   9,   4,   4,  47],\n",
            "        [ 25,  12,  63,  10,  65,   4,  35,   4,   4, 216],\n",
            "        [ 14,  66,  14,  15,  12,  44,  40,   4,   7,  40],\n",
            "        [  4, 220,   4,  12, 189,   4,  84,   9,  10,   4],\n",
            "        [ 92,   4,  14,   4,  25, 241,  12,   0,  14,  25],\n",
            "        [ 29,   2,  53,  15,  15, 161,   2,   2, 123,  91],\n",
            "        [ 11,  83, 195,  24, 127, 101,  58,  55,  55,  58]]), 'sex': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'age': tensor([[45, 45, 45, 45, 45, 45, 45, 45, 45, 45],\n",
            "        [35, 35, 35, 35, 35, 35, 35, 35, 35, 35],\n",
            "        [45, 45, 45, 45, 45, 45, 45, 45, 45, 45],\n",
            "        [18, 18, 18, 18, 18, 18, 18, 18, 18, 18],\n",
            "        [25, 25, 25, 25, 25, 25, 25, 25, 25, 25],\n",
            "        [50, 50, 50, 50, 50, 50, 50, 50, 50, 50],\n",
            "        [18, 18, 18, 18, 18, 18, 18, 18, 18, 18],\n",
            "        [25, 25, 25, 25, 25, 25, 25, 25, 25, 25],\n",
            "        [25, 25, 25, 25, 25, 25, 25, 25, 25, 25],\n",
            "        [25, 25, 25, 25, 25, 25, 25, 25, 25, 25]]), 'occupation': tensor([[ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
            "        [15, 15, 15, 15, 15, 15, 15, 15, 15, 15],\n",
            "        [ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2],\n",
            "        [17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
            "        [ 7,  7,  7,  7,  7,  7,  7,  7,  7,  7],\n",
            "        [ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
            "        [ 4,  4,  4,  4,  4,  4,  4,  4,  4,  4],\n",
            "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "        [ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2],\n",
            "        [14, 14, 14, 14, 14, 14, 14, 14, 14, 14]])}\n",
            "1 {'user_id': tensor([[1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000],\n",
            "        [4901, 4901, 4901, 4901, 4901, 4901, 4901, 4901, 4901, 4901],\n",
            "        [1579, 1579, 1579, 1579, 1579, 1579, 1579, 1579, 1579, 1579],\n",
            "        [1582, 1582, 1582, 1582, 1582, 1582, 1582, 1582, 1582, 1582],\n",
            "        [4458, 4458, 4458, 4458, 4458, 4458, 4458, 4458, 4458, 4458],\n",
            "        [4150, 4150, 4150, 4150, 4150, 4150, 4150, 4150, 4150, 4150],\n",
            "        [3483, 3483, 3483, 3483, 3483, 3483, 3483, 3483, 3483, 3483],\n",
            "        [5071, 5071, 5071, 5071, 5071, 5071, 5071, 5071, 5071, 5071],\n",
            "        [3050, 3050, 3050, 3050, 3050, 3050, 3050, 3050, 3050, 3050],\n",
            "        [1947, 1947, 1947, 1947, 1947, 1947, 1947, 1947, 1947, 1947]]), 'movie_id': tensor([[2018, 2687, 2137,  595, 2080, 3751, 2700,  594, 1029, 2085],\n",
            "        [ 527, 1674, 3102, 1100, 1210, 3147, 2762, 3006, 2628, 3081],\n",
            "        [2580, 2606,  785, 2502, 2581, 2013, 2598, 2763, 2701, 2788],\n",
            "        [2125, 1221, 1721,  110,  998, 2006,  457, 1387, 1499, 2188],\n",
            "        [1295, 3521, 1199, 3683, 1198, 1228, 1674, 3090, 1222, 1307],\n",
            "        [ 231, 2374, 2311, 1409, 2881, 2249, 3258, 2405,  174,  303],\n",
            "        [1503, 1459,  344, 3206, 3841, 2792, 2791, 1214, 3701, 3250],\n",
            "        [ 380, 2872, 2353, 2457, 3256, 2414, 1580, 2406, 2115,  648],\n",
            "        [2527, 2454,  316, 1653, 2407,  198, 2699, 1876,  674, 3698],\n",
            "        [3703, 1218, 2692, 1201, 3267, 1240,  260, 1214, 1912, 2947]]), 'rating': tensor([[3., 4., 3., 5., 4., 4., 4., 3., 3., 4.],\n",
            "        [4., 4., 4., 3., 5., 4., 5., 4., 4., 4.],\n",
            "        [4., 3., 4., 4., 4., 4., 3., 2., 2., 2.],\n",
            "        [5., 3., 5., 5., 3., 3., 2., 4., 3., 3.],\n",
            "        [3., 4., 3., 4., 5., 4., 3., 4., 2., 4.],\n",
            "        [4., 3., 4., 3., 3., 3., 2., 3., 2., 3.],\n",
            "        [3., 3., 3., 4., 4., 2., 2., 3., 3., 3.],\n",
            "        [5., 4., 4., 4., 4., 3., 4., 4., 4., 4.],\n",
            "        [4., 2., 3., 4., 4., 4., 2., 3., 5., 4.],\n",
            "        [5., 4., 4., 5., 4., 4., 5., 4., 4., 4.]], dtype=torch.float64), 'genres': tensor([[ 11,  11,  11,  83, 232,   0, 164,  83,  83,  11],\n",
            "        [ 25, 208,  16, 161, 170,  14,  16,  12,  69, 187],\n",
            "        [ 42,  10,   4,   2,   2,  27,   4,  38, 268,   4],\n",
            "        [ 15,  26,  15,  40,  71,  13,  38, 186,   8,  12],\n",
            "        [ 12,  88, 118, 296,  27,  12, 208,  12,  40,   2],\n",
            "        [  4,   3, 174,   2,  38,   4,   4,  87,   4,  73],\n",
            "        [  4,  67,   4,  20,  81,   4,   4, 171, 189,  12],\n",
            "        [ 87, 273,  38,  81,  38, 114, 197,  87,  27, 114],\n",
            "        [261,  58,  56, 207,  66,  59, 267, 217,  21,  56],\n",
            "        [ 86,  38, 106, 168,  38,  55,  69, 171, 106,   7]]), 'sex': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'age': tensor([[25, 25, 25, 25, 25, 25, 25, 25, 25, 25],\n",
            "        [25, 25, 25, 25, 25, 25, 25, 25, 25, 25],\n",
            "        [25, 25, 25, 25, 25, 25, 25, 25, 25, 25],\n",
            "        [18, 18, 18, 18, 18, 18, 18, 18, 18, 18],\n",
            "        [25, 25, 25, 25, 25, 25, 25, 25, 25, 25],\n",
            "        [25, 25, 25, 25, 25, 25, 25, 25, 25, 25],\n",
            "        [45, 45, 45, 45, 45, 45, 45, 45, 45, 45],\n",
            "        [25, 25, 25, 25, 25, 25, 25, 25, 25, 25],\n",
            "        [35, 35, 35, 35, 35, 35, 35, 35, 35, 35],\n",
            "        [25, 25, 25, 25, 25, 25, 25, 25, 25, 25]]), 'occupation': tensor([[ 6,  6,  6,  6,  6,  6,  6,  6,  6,  6],\n",
            "        [ 7,  7,  7,  7,  7,  7,  7,  7,  7,  7],\n",
            "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "        [ 4,  4,  4,  4,  4,  4,  4,  4,  4,  4],\n",
            "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "        [ 7,  7,  7,  7,  7,  7,  7,  7,  7,  7],\n",
            "        [ 7,  7,  7,  7,  7,  7,  7,  7,  7,  7],\n",
            "        [12, 12, 12, 12, 12, 12, 12, 12, 12, 12],\n",
            "        [ 7,  7,  7,  7,  7,  7,  7,  7,  7,  7]])}\n",
            "2 {'user_id': tensor([[5718, 5718, 5718, 5718, 5718, 5718, 5718, 5718, 5718, 5718],\n",
            "        [5599, 5599, 5599, 5599, 5599, 5599, 5599, 5599, 5599, 5599],\n",
            "        [1912, 1912, 1912, 1912, 1912, 1912, 1912, 1912, 1912, 1912],\n",
            "        [1489, 1489, 1489, 1489, 1489, 1489, 1489, 1489, 1489, 1489],\n",
            "        [4016, 4016, 4016, 4016, 4016, 4016, 4016, 4016, 4016, 4016],\n",
            "        [2757, 2757, 2757, 2757, 2757, 2757, 2757, 2757, 2757, 2757],\n",
            "        [4005, 4005, 4005, 4005, 4005, 4005, 4005, 4005, 4005, 4005],\n",
            "        [3778, 3778, 3778, 3778, 3778, 3778, 3778, 3778, 3778, 3778],\n",
            "        [ 516,  516,  516,  516,  516,  516,  516,  516,  516,  516],\n",
            "        [3065, 3065, 3065, 3065, 3065, 3065, 3065, 3065, 3065, 3065]]), 'movie_id': tensor([[2391,  314,  529,  588,  628, 1535, 1411, 2331,  475, 2426],\n",
            "        [ 293,   58, 1912, 3358,  356, 1770,  838,   85,  821,  440],\n",
            "        [1970, 2947,  903,  965, 2176, 2186, 2181, 2180,  930, 3363],\n",
            "        [2713, 3174, 3053, 3623, 2568, 2622, 3752, 2805, 3354, 2581],\n",
            "        [2160, 3256,  481, 3204,  454, 1608, 3849, 3420,  377, 1805],\n",
            "        [1859, 1193, 1225,  162,  608, 2804, 1294,  296, 2204, 1219],\n",
            "        [1645, 1805, 1092,  648, 1733,  539, 2539, 2762, 2976, 3173],\n",
            "        [ 606, 2026, 2719, 1762, 1996, 1998, 1969, 1987, 2338, 2119],\n",
            "        [3897, 1172, 1270, 1136, 1304, 2248, 3504, 1294, 2289,    1],\n",
            "        [1208, 1219, 1197, 1307, 2918, 2248, 1968, 3911, 3499, 1270]]), 'rating': tensor([[4., 5., 5., 4., 5., 3., 5., 3., 4., 4.],\n",
            "        [4., 5., 5., 4., 5., 3., 4., 4., 1., 4.],\n",
            "        [1., 4., 2., 4., 4., 4., 2., 3., 4., 3.],\n",
            "        [1., 1., 2., 1., 1., 2., 1., 1., 1., 1.],\n",
            "        [4., 1., 3., 3., 4., 3., 4., 3., 5., 3.],\n",
            "        [3., 5., 5., 5., 5., 4., 4., 5., 4., 5.],\n",
            "        [5., 4., 5., 5., 3., 5., 5., 4., 3., 4.],\n",
            "        [1., 2., 3., 2., 1., 1., 1., 1., 1., 1.],\n",
            "        [3., 3., 3., 3., 5., 3., 3., 4., 3., 3.],\n",
            "        [4., 3., 5., 4., 5., 3., 4., 5., 4., 5.]], dtype=torch.float64), 'genres': tensor([[ 28,  12,  12, 108,  14,  15,  12,   2,  12,   9],\n",
            "        [ 72,  15, 106,   2,  80, 145,   9,  15,  20,   2],\n",
            "        [ 46,   7,  67,  16,  16,  76,  16,  16, 146,   3],\n",
            "        [ 74,   3,  25,  38,  71, 163,   4,   2, 118,   2],\n",
            "        [ 74,  38,  14,  16,  14,  38,  16,  14,  51, 214],\n",
            "        [ 12,  12,  12,  24,  18,   3,  48,  63,  16,  74],\n",
            "        [205, 214,  67, 114,  15,   2,   4,  16,  65,  12],\n",
            "        [ 46,  74,  74, 112,  74,  46,  46,  46, 204,  46],\n",
            "        [  3,   9,  66,   4,  85,   9,   3,  48,   3,   0],\n",
            "        [ 25,  74,  87,   2,   4,   9,   3,   4,  46,  66]]), 'sex': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'age': tensor([[35, 35, 35, 35, 35, 35, 35, 35, 35, 35],\n",
            "        [35, 35, 35, 35, 35, 35, 35, 35, 35, 35],\n",
            "        [25, 25, 25, 25, 25, 25, 25, 25, 25, 25],\n",
            "        [35, 35, 35, 35, 35, 35, 35, 35, 35, 35],\n",
            "        [50, 50, 50, 50, 50, 50, 50, 50, 50, 50],\n",
            "        [25, 25, 25, 25, 25, 25, 25, 25, 25, 25],\n",
            "        [35, 35, 35, 35, 35, 35, 35, 35, 35, 35],\n",
            "        [25, 25, 25, 25, 25, 25, 25, 25, 25, 25],\n",
            "        [56, 56, 56, 56, 56, 56, 56, 56, 56, 56],\n",
            "        [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]]), 'occupation': tensor([[14, 14, 14, 14, 14, 14, 14, 14, 14, 14],\n",
            "        [ 7,  7,  7,  7,  7,  7,  7,  7,  7,  7],\n",
            "        [ 4,  4,  4,  4,  4,  4,  4,  4,  4,  4],\n",
            "        [ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2],\n",
            "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "        [ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2],\n",
            "        [ 7,  7,  7,  7,  7,  7,  7,  7,  7,  7],\n",
            "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "        [14, 14, 14, 14, 14, 14, 14, 14, 14, 14],\n",
            "        [ 4,  4,  4,  4,  4,  4,  4,  4,  4,  4]])}\n",
            "3 {'user_id': tensor([[1117, 1117, 1117, 1117, 1117, 1117, 1117, 1117, 1117, 1117],\n",
            "        [1941, 1941, 1941, 1941, 1941, 1941, 1941, 1941, 1941, 1941],\n",
            "        [1860, 1860, 1860, 1860, 1860, 1860, 1860, 1860, 1860, 1860],\n",
            "        [5080, 5080, 5080, 5080, 5080, 5080, 5080, 5080, 5080, 5080],\n",
            "        [3842, 3842, 3842, 3842, 3842, 3842, 3842, 3842, 3842, 3842],\n",
            "        [1974, 1974, 1974, 1974, 1974, 1974, 1974, 1974, 1974, 1974],\n",
            "        [2244, 2244, 2244, 2244, 2244, 2244, 2244, 2244, 2244, 2244],\n",
            "        [4812, 4812, 4812, 4812, 4812, 4812, 4812, 4812, 4812, 4812],\n",
            "        [4431, 4431, 4431, 4431, 4431, 4431, 4431, 4431, 4431, 4431],\n",
            "        [4285, 4285, 4285, 4285, 4285, 4285, 4285, 4285, 4285, 4285]]), 'movie_id': tensor([[1193, 1080, 2788, 1387, 3421, 1278, 2866, 2116, 1073, 3671],\n",
            "        [2540, 2989, 3197, 2006, 2023, 3519, 2414, 2115, 2991,  145],\n",
            "        [  62, 1277,  852, 1370, 3566, 3328, 3408, 3185, 3624, 3623],\n",
            "        [1587, 2002,  434, 2431,  736, 3113, 1033,  835, 3660, 3771],\n",
            "        [2417, 2264, 1985, 1983, 2147, 1972, 1986, 2450, 2122, 1977],\n",
            "        [1252, 1267, 1248, 2203, 3683, 3334,  942, 3706, 1212, 3746],\n",
            "        [2193, 2105, 2054, 1267,  922, 1252,  930,  541,  913, 3683],\n",
            "        [1523,    6,  493,  942, 1500,  555, 1396, 1179, 2000,   47],\n",
            "        [1281, 1198, 1206,   32,  296,  904, 1219, 1199, 2348, 2501],\n",
            "        [ 798, 3841, 2701, 2153, 2422, 3766,  899,  356, 1944, 1247]]), 'rating': tensor([[5., 4., 5., 4., 4., 5., 4., 3., 5., 4.],\n",
            "        [3., 4., 5., 4., 3., 3., 3., 3., 5., 2.],\n",
            "        [3., 2., 3., 2., 2., 3., 4., 3., 3., 3.],\n",
            "        [3., 4., 3., 4., 5., 4., 4., 5., 4., 5.],\n",
            "        [3., 4., 1., 3., 1., 1., 1., 1., 2., 1.],\n",
            "        [4., 4., 5., 5., 4., 3., 4., 3., 5., 4.],\n",
            "        [4., 3., 2., 5., 5., 5., 5., 4., 5., 5.],\n",
            "        [4., 3., 3., 2., 4., 5., 4., 4., 4., 5.],\n",
            "        [5., 3., 4., 1., 4., 2., 5., 4., 5., 2.],\n",
            "        [3., 3., 5., 2., 3., 3., 3., 5., 3., 2.]], dtype=torch.float64), 'genres': tensor([[ 12,   4,   4, 186,   4,  10,  12, 241, 159,  92],\n",
            "        [223,   7,   7,  13,  26, 257, 114,  27,   7,   7],\n",
            "        [ 12, 181,   2,  38,   3,  63,  12,  12,   7,  38],\n",
            "        [ 27, 191,  41,   3, 123,  38,  11,  12,  90,  27],\n",
            "        [  3,  12,  46,  46,  12,  46,  46, 230,  74,  46],\n",
            "        [175,  76, 121,  76, 296, 287, 147, 175,  67,  25],\n",
            "        [116,  69, 231,  76, 126, 175, 146, 101, 141, 296],\n",
            "        [106,   5,  26, 147, 129, 106, 189, 165, 191,  28],\n",
            "        [  4,  27, 118,  19,  63,  67,  74, 118,  12,  12],\n",
            "        [  8,  81, 268,  27, 182, 257, 138,  80,  45,  15]]), 'sex': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'age': tensor([[18, 18, 18, 18, 18, 18, 18, 18, 18, 18],\n",
            "        [35, 35, 35, 35, 35, 35, 35, 35, 35, 35],\n",
            "        [56, 56, 56, 56, 56, 56, 56, 56, 56, 56],\n",
            "        [50, 50, 50, 50, 50, 50, 50, 50, 50, 50],\n",
            "        [35, 35, 35, 35, 35, 35, 35, 35, 35, 35],\n",
            "        [35, 35, 35, 35, 35, 35, 35, 35, 35, 35],\n",
            "        [ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
            "        [18, 18, 18, 18, 18, 18, 18, 18, 18, 18],\n",
            "        [ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
            "        [35, 35, 35, 35, 35, 35, 35, 35, 35, 35]]), 'occupation': tensor([[14, 14, 14, 14, 14, 14, 14, 14, 14, 14],\n",
            "        [17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
            "        [16, 16, 16, 16, 16, 16, 16, 16, 16, 16],\n",
            "        [12, 12, 12, 12, 12, 12, 12, 12, 12, 12],\n",
            "        [16, 16, 16, 16, 16, 16, 16, 16, 16, 16],\n",
            "        [17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
            "        [10, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
            "        [14, 14, 14, 14, 14, 14, 14, 14, 14, 14],\n",
            "        [14, 14, 14, 14, 14, 14, 14, 14, 14, 14],\n",
            "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])}\n"
          ]
        }
      ],
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=10, shuffle=True, num_workers=2)\n",
        "val_dataloader = DataLoader(test_dataset, batch_size=10, shuffle=True, num_workers=2)\n",
        "\n",
        "for i_batch, sample in enumerate(val_dataloader):\n",
        "    print(i_batch, sample)\n",
        "    if i_batch == 3:\n",
        "        break\n"
      ],
      "id": "Yc4-R7_gNTNF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5KD5TezcSYw",
        "outputId": "679ff0b4-90c2-4637-aad1-4cb8e25590a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40842\n"
          ]
        }
      ],
      "source": [
        "print(len(train_dataloader))"
      ],
      "id": "f5KD5TezcSYw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation?"
      ],
      "metadata": {
        "id": "jSGZuoDPHw3T"
      },
      "id": "jSGZuoDPHw3T"
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_mode = True"
      ],
      "metadata": {
        "id": "Dhnoz6PzHt80"
      },
      "id": "Dhnoz6PzHt80",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOsDsuxxpgCp"
      },
      "source": [
        "# Transformer"
      ],
      "id": "jOsDsuxxpgCp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3539f61f-fe7d-4428-b074-327a883f7f6e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "3539f61f-fe7d-4428-b074-327a883f7f6e"
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "np.random.seed(0)"
      ],
      "metadata": {
        "id": "kj9T-RlBLqq9"
      },
      "id": "kj9T-RlBLqq9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c72c2ada-2106-4505-82f5-086e518080a5"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, model_dim, dropout_p, max_len):\n",
        "        super().__init__()\n",
        "        # Modified version from: https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
        "        # max_len determines how far the position can have an effect on a token (window)\n",
        "        \n",
        "        # Info\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        \n",
        "        # Encoding - From formula\n",
        "        pos_encoding = torch.zeros(max_len, model_dim)\n",
        "        positions_list = torch.arange(0, max_len, dtype=torch.float).view(-1, 1) # 0, 1, 2, 3, 4, 5\n",
        "        division_term = torch.exp(torch.arange(0, model_dim, 2).float() * (-math.log(10000.0)) / model_dim) # 1000^(2i/model_dim)\n",
        "        \n",
        "        # PE(pos, 2i) = sin(pos/1000^(2i/model_dim))\n",
        "        pos_encoding[:, 0::2] = torch.sin(positions_list * division_term)\n",
        "        \n",
        "        # PE(pos, 2i + 1) = cos(pos/1000^(2i/model_dim))\n",
        "        pos_encoding[:, 1::2] = torch.cos(positions_list * division_term)\n",
        "        \n",
        "        # Saving buffer (same as parameter without gradients needed)\n",
        "        pos_encoding = pos_encoding.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer(\"pos_encoding\", pos_encoding)\n",
        "        \n",
        "    def forward(self, token_embedding: torch.tensor) -> torch.tensor:\n",
        "        # Residual connection + pos encoding\n",
        "        return self.dropout(token_embedding + self.pos_encoding[:token_embedding.size(0), :])"
      ],
      "id": "c72c2ada-2106-4505-82f5-086e518080a5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "588b2729-866c-470a-aca7-6a3c5ea0b192"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    \"\"\"\n",
        "    Model from \"A detailed guide to Pytorch's nn.Transformer() module.\", by Daniel Melchor: https://medium.com/p/c80afbc9ffb1/\n",
        "    \"\"\"\n",
        "    # Constructor\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_dim,\n",
        "        num_heads,\n",
        "        num_encoder_layers,\n",
        "        num_decoder_layers,\n",
        "        dropout_p,\n",
        "        num_users=6041,\n",
        "        num_movies=3953,\n",
        "        num_genres=301,\n",
        "        num_sex=2, \n",
        "        num_age=60,\n",
        "        num_occupation=21,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.model_dim = model_dim\n",
        "        self.positional_encoder = PositionalEncoding(\n",
        "            model_dim=model_dim, dropout_p=dropout_p, max_len=5000\n",
        "        )\n",
        "        self.user_embedding = nn.Embedding(num_users, model_dim)\n",
        "        self.movie_embedding = nn.Embedding(num_movies, model_dim)\n",
        "        self.genre_embedding = nn.Embedding(num_genres, model_dim)\n",
        "        self.sex_embedding = nn.Embedding(num_sex, model_dim)\n",
        "        self.age_embedding = nn.Embedding(num_age, model_dim)\n",
        "        self.occupation_embedding = nn.Embedding(num_occupation, model_dim)\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=model_dim,\n",
        "            nhead=num_heads,\n",
        "            num_encoder_layers=num_encoder_layers,\n",
        "            num_decoder_layers=num_decoder_layers,\n",
        "            dropout=dropout_p,\n",
        "        )\n",
        "\n",
        "        # Regression\n",
        "        self.out = nn.Linear(model_dim, 1)\n",
        "        \n",
        "    def forward(self, user, movie, genre, sex, age, occupation, rating, mask=None):\n",
        "        movie = self.movie_embedding(movie) * math.sqrt(self.model_dim)\n",
        "        user = self.user_embedding(user) * math.sqrt(self.model_dim)\n",
        "        genre = self.genre_embedding(genre) * math.sqrt(self.model_dim)\n",
        "        sex = self.sex_embedding(sex) * math.sqrt(self.model_dim)\n",
        "        age = self.age_embedding(age) * math.sqrt(self.model_dim)\n",
        "        occupation = self.occupation_embedding(occupation) * math.sqrt(self.model_dim)\n",
        "\n",
        "        #print(movie)\n",
        "        feature_embedding = movie + user + genre + sex + age + occupation\n",
        "        features = self.positional_encoder(feature_embedding) \n",
        "        features = features.permute(1,0,2)\n",
        "        \n",
        "        transformer_out = self.transformer(features, features, mask)\n",
        "        transformer_out = transformer_out.permute(1,0,2)\n",
        "        out = self.out(transformer_out)\n",
        "        \n",
        "        return out\n",
        "      \n",
        "    def get_tgt_mask(self, size) -> torch.tensor:\n",
        "        mask = torch.tril(torch.ones(size, size) == 1) # Lower triangular matrix\n",
        "        mask = mask.float()\n",
        "        mask = mask.masked_fill(mask == 0, float('-inf')) # Convert zeros to -inf\n",
        "        mask = mask.masked_fill(mask == 1, float(0.0)) # Convert ones to 0\n",
        "        \n",
        "        # EX for size=5:\n",
        "        # [[0., -inf, -inf, -inf, -inf],\n",
        "        #  [0.,   0., -inf, -inf, -inf],\n",
        "        #  [0.,   0.,   0., -inf, -inf],\n",
        "        #  [0.,   0.,   0.,   0., -inf],\n",
        "        #  [0.,   0.,   0.,   0.,   0.]]\n",
        "        \n",
        "        return mask\n",
        "    \n",
        "    def create_pad_mask(self, matrix: torch.tensor, pad_token: int) -> torch.tensor:\n",
        "        # If matrix = [1,2,3,0,0,0] where pad_token=0, the result mask is\n",
        "        # [False, False, False, True, True, True]\n",
        "        return (matrix == pad_token)"
      ],
      "id": "588b2729-866c-470a-aca7-6a3c5ea0b192"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4d04a60a-f013-4eda-b056-fc9bb1b1ea79"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = Transformer(\n",
        "    model_dim=16, num_heads=2, num_encoder_layers=3, num_decoder_layers=3, dropout_p=0.1\n",
        ").to(device)\n",
        "if os.path.exists('trained_trans_10_epochs.pth'):\n",
        "    model.load_state_dict(torch.load('trained_trans_10_epochs.pth'))\n",
        "model.train()\n",
        "opt = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "loss_fn = nn.MSELoss()"
      ],
      "id": "4d04a60a-f013-4eda-b056-fc9bb1b1ea79"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bc6949f-2d59-44c3-8198-037e115106aa"
      },
      "outputs": [],
      "source": [
        "def train_loop(model, opt, loss_fn, dataloader):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(dataloader):\n",
        "        if i % 100 == 0:\n",
        "            print(i)\n",
        "        users, movies = batch['user_id'], batch['movie_id']\n",
        "        genres, sex = batch['genres'], batch['sex']\n",
        "        age, occupation = batch['age'], batch['occupation']\n",
        "        ratings = batch['rating']\n",
        "        users, movies =  users.long().to(device), movies.long().to(device)\n",
        "        genres, sex = genres.long().to(device), sex.long().to(device)\n",
        "        age, occupation = age.long().to(device), occupation.long().to(device)\n",
        "        ratings = torch.tensor(ratings).float().to(device) \n",
        "\n",
        "        #print(users, movies)\n",
        "        sequence_length = ratings.size(1)\n",
        "        batch_len = ratings.size(0)\n",
        "        mask = model.get_tgt_mask(sequence_length).to(device)\n",
        "        # Standard training except we pass in y_input and tgt_mask\n",
        "        pred = model(users, movies, genres, sex, age, occupation, mask)\n",
        "        # print(pred.shape, ratings.shape)\n",
        "        loss = loss_fn(pred.squeeze(dim=-1), ratings)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        total_loss += loss.detach().item()\n",
        "        \n",
        "    return total_loss / len(dataloader)"
      ],
      "id": "7bc6949f-2d59-44c3-8198-037e115106aa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c23630c9-ce84-4996-8d8c-ff7919303331"
      },
      "outputs": [],
      "source": [
        "def validation_loop(model, loss_fn, dataloader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            users, movies = batch['user_id'], batch['movie_id']\n",
        "            genres, sex = batch['genres'], batch['sex']\n",
        "            age, occupation = batch['age'], batch['occupation']\n",
        "            ratings = batch['rating']\n",
        "            #print(users.shape, movies.shape)\n",
        "            users, movies =  users.long().to(device), movies.long().to(device)\n",
        "            genres, sex = genres.long().to(device), sex.long().to(device)\n",
        "            age, occupation = age.long().to(device), occupation.long().to(device)\n",
        "            ratings = torch.tensor(ratings).float().to(device) \n",
        "\n",
        "            loss = 0\n",
        "            #print(users, movies)\n",
        "            sequence_length = ratings.size(1)\n",
        "            batch_len = ratings.size(0)\n",
        "            mask = model.get_tgt_mask(sequence_length).to(device)\n",
        "            # Standard training except we pass in y_input and tgt_mask\n",
        "            pred = model(users, movies, genres, sex, age, occupation, mask)\n",
        "            loss = loss_fn(pred.squeeze(dim=-1), ratings)\n",
        "\n",
        "            total_loss += loss.detach().item()\n",
        "        \n",
        "    return total_loss / len(dataloader)"
      ],
      "id": "c23630c9-ce84-4996-8d8c-ff7919303331"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5e57ba93-cc8f-4b12-870f-6aed4dce94ab"
      },
      "outputs": [],
      "source": [
        "def fit(model, opt, loss_fn, train_dataloader, val_dataloader, epochs):\n",
        "    # Used for plotting later on\n",
        "    train_loss_list, validation_loss_list = [], []\n",
        "    val_accs = []\n",
        "    \n",
        "    print(\"Training and validating model\")\n",
        "    for epoch in range(epochs):\n",
        "        print(\"-\"*25, f\"Epoch {epoch + 1}\",\"-\"*25)\n",
        "        \n",
        "        train_loss = train_loop(model, opt, loss_fn, train_dataloader)\n",
        "        train_loss_list += [train_loss]\n",
        "        \n",
        "        validation_loss = validation_loop(model, loss_fn, val_dataloader)\n",
        "        validation_loss_list += [validation_loss]\n",
        "        \n",
        "        print(f\"Training loss: {train_loss: .4f}\")\n",
        "        print(f\"Validation loss: {validation_loss: .4f}\")\n",
        "        \n",
        "    return train_loss_list, validation_loss_list"
      ],
      "id": "5e57ba93-cc8f-4b12-870f-6aed4dce94ab"
    },
    {
      "cell_type": "code",
      "source": [
        "if not evaluation_mode:\n",
        "    train_loss_list, validation_loss_list = fit(model, opt, loss_fn, train_dataloader, val_dataloader, 10)"
      ],
      "metadata": {
        "id": "V-i7BmEhHhsL"
      },
      "id": "V-i7BmEhHhsL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40f805ad-7748-4785-9066-c5500287a4af"
      },
      "outputs": [],
      "source": [
        "if not evaluation_mode:\n",
        "    plt.plot(train_loss_list, label = \"Train loss\")\n",
        "    plt.plot(validation_loss_list, label = \"Validation loss\")\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Loss vs Epoch')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "id": "40f805ad-7748-4785-9066-c5500287a4af"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wH2xE1OLVbVH"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'trained_trans_10_epochs.pth')"
      ],
      "id": "wH2xE1OLVbVH"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-_6u25fpnu2"
      },
      "source": [
        "# LSTM\n"
      ],
      "id": "Y-_6u25fpnu2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6YIDciwpnec"
      },
      "outputs": [],
      "source": [
        "class LSTM_Model(nn.Module):\n",
        "    \"\"\"\n",
        "    Model from \"A detailed guide to Pytorch's nn.Transformer() module.\", by Daniel Melchor: https://medium.com/p/c80afbc9ffb1/\n",
        "    \"\"\"\n",
        "    # Constructor\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_dim,       \n",
        "        dropout_p,\n",
        "        num_users=6041,\n",
        "        num_movies=3953,\n",
        "        num_genres=301,\n",
        "        num_ratings=5,\n",
        "        num_sex=2, \n",
        "        num_age=60,\n",
        "        num_occupation=21,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # INFO\n",
        "        self.model_type = \"Transformer\"\n",
        "        self.model_dim = model_dim\n",
        "        self.user_embedding = nn.Embedding(num_users, model_dim)\n",
        "        self.movie_embedding = nn.Embedding(num_movies, model_dim)\n",
        "        self.genre_embedding = nn.Embedding(num_genres, model_dim)\n",
        "        self.sex_embedding = nn.Embedding(num_sex, model_dim)\n",
        "        self.age_embedding = nn.Embedding(num_age, model_dim)\n",
        "        self.occupation_embedding = nn.Embedding(num_occupation, model_dim)\n",
        "        self.lstm = nn.LSTM(model_dim, model_dim * 2, 3, dropout=dropout_p, batch_first=True)\n",
        "        # Regression\n",
        "        self.out = nn.Linear(model_dim * 2, 1)\n",
        "        \n",
        "    def forward(self, user, movie, genre, sex, age, occupation):\n",
        "        movie = self.movie_embedding(movie) * math.sqrt(self.model_dim)\n",
        "        user = self.user_embedding(user) * math.sqrt(self.model_dim)\n",
        "        genre = self.genre_embedding(genre) * math.sqrt(self.model_dim)\n",
        "        sex = self.sex_embedding(sex) * math.sqrt(self.model_dim)\n",
        "        age = self.age_embedding(age) * math.sqrt(self.model_dim)\n",
        "        occupation = self.occupation_embedding(occupation) * math.sqrt(self.model_dim)\n",
        "\n",
        "        feature_embedding = movie + user + genre + sex + age + occupation\n",
        "        \n",
        "        output, _ = self.lstm(feature_embedding)\n",
        "        return self.out(output)\n",
        "    "
      ],
      "id": "J6YIDciwpnec"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0gIAeYX3iiD"
      },
      "outputs": [],
      "source": [
        "def lstm_train_loop(model, opt, loss_fn, dataloader):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in dataloader:\n",
        "        users, movies = batch['user_id'], batch['movie_id']\n",
        "        genres, sex = batch['genres'], batch['sex']\n",
        "        age, occupation = batch['age'], batch['occupation']\n",
        "        ratings = batch['rating']\n",
        "        users, movies =  torch.tensor(users).long().to(device), torch.tensor(movies).long().to(device)\n",
        "        genres, sex = torch.tensor(genres).long().to(device), torch.tensor(sex).long().to(device)\n",
        "        age, occupation = torch.tensor(age).long().to(device), torch.tensor(occupation).long().to(device)\n",
        "        ratings = torch.tensor(ratings).float().to(device)\n",
        "\n",
        "        pred = model(users, movies, genres, sex, age, occupation)\n",
        "        loss = loss_fn(pred.squeeze(dim=-1), ratings)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "    \n",
        "        total_loss += loss.detach().item()\n",
        "        \n",
        "    return total_loss / len(dataloader)"
      ],
      "id": "T0gIAeYX3iiD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpY3ZAp_6Vz-"
      },
      "outputs": [],
      "source": [
        "def lstm_eval_loop(model, loss_fn, dataloader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_acc = 0.0\n",
        "    for batch in dataloader:\n",
        "        users, movies = batch['user_id'], batch['movie_id']\n",
        "        genres, sex = batch['genres'], batch['sex']\n",
        "        age, occupation = batch['age'], batch['occupation']\n",
        "        ratings = batch['rating']\n",
        "        users, movies =  torch.tensor(users).long().to(device), torch.tensor(movies).long().to(device)\n",
        "        genres, sex = torch.tensor(genres).long().to(device), torch.tensor(sex).long().to(device)\n",
        "        age, occupation = torch.tensor(age).long().to(device), torch.tensor(occupation).long().to(device)\n",
        "        ratings = torch.tensor(ratings).float().to(device) \n",
        "\n",
        "        pred = model(users, movies, genres, sex, age, occupation)\n",
        "        loss = loss_fn(pred.squeeze(dim=-1), ratings)\n",
        "        total_loss += loss.detach().item()\n",
        "\n",
        "    return total_loss / len(dataloader)"
      ],
      "id": "YpY3ZAp_6Vz-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_bGcOYgQF28"
      },
      "outputs": [],
      "source": [
        "lstm_model = LSTM_Model(\n",
        "    model_dim=16, dropout_p=0.1\n",
        ").to(device)\n",
        "if os.path.exists('trained_lstm_10_epochs.pth'):\n",
        "    lstm_model.load_state_dict(torch.load('trained_lstm_10_epochs.pth'))\n",
        "lstm_model.train()\n",
        "lstm_opt = torch.optim.SGD(lstm_model.parameters(), lr=0.01)\n",
        "lstm_loss_fn = torch.nn.MSELoss()"
      ],
      "id": "D_bGcOYgQF28"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4de2CyW7wip"
      },
      "outputs": [],
      "source": [
        "def fit_lstm(model, opt, loss_fn, train_dataloader, val_dataloader, epochs):\n",
        "    # Used for plotting later on\n",
        "    train_loss_list, validation_loss_list = [], []\n",
        "    val_accs = []\n",
        "    \n",
        "    print(\"Training and validating model\")\n",
        "    for epoch in range(epochs):\n",
        "        print(\"-\"*25, f\"Epoch {epoch + 1}\",\"-\"*25)\n",
        "        \n",
        "        train_loss = lstm_train_loop(model, opt, loss_fn, train_dataloader)\n",
        "        train_loss_list += [train_loss]\n",
        "        \n",
        "        validation_loss = lstm_eval_loop(model, loss_fn, val_dataloader)\n",
        "        validation_loss_list += [validation_loss]\n",
        "        \n",
        "        print(f\"Training MSE loss: {train_loss: .4f}\")\n",
        "        print(f\"Validation MSE loss: {validation_loss: .4f}\")\n",
        "        \n",
        "    return train_loss_list, validation_loss_list, val_accs"
      ],
      "id": "k4de2CyW7wip"
    },
    {
      "cell_type": "code",
      "source": [
        "if not evaluation_mode:\n",
        "    lstm_train_loss_list, lstm_validation_loss_list, lstm_v_accs = fit_lstm(lstm_model, lstm_opt, lstm_loss_fn, train_dataloader, val_dataloader, 10)"
      ],
      "metadata": {
        "id": "CpjJEHCDH2QV"
      },
      "id": "CpjJEHCDH2QV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZ7ZT-yF79hX"
      },
      "outputs": [],
      "source": [
        "if not evaluation_mode:\n",
        "    plt.plot(lstm_train_loss_list, label = \"Train loss\")\n",
        "    plt.plot(lstm_validation_loss_list, label = \"Validation loss\")\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Loss vs Epoch')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "id": "UZ7ZT-yF79hX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIms7uzXl2Z4"
      },
      "outputs": [],
      "source": [
        "torch.save(lstm_model.state_dict(), 'trained_lstm_10_epochs.pth')"
      ],
      "id": "eIms7uzXl2Z4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dBgGMHalXRs"
      },
      "source": [
        "# Evaluation"
      ],
      "id": "7dBgGMHalXRs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVMfyWMzlR-C",
        "outputId": "51226891-1ed5-43b6-b69a-4d22e57c9e92"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (positional_encoder): PositionalEncoding(\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (user_embedding): Embedding(6041, 16)\n",
              "  (movie_embedding): Embedding(3953, 16)\n",
              "  (genre_embedding): Embedding(301, 16)\n",
              "  (sex_embedding): Embedding(2, 16)\n",
              "  (age_embedding): Embedding(60, 16)\n",
              "  (occupation_embedding): Embedding(21, 16)\n",
              "  (transformer): Transformer(\n",
              "    (encoder): TransformerEncoder(\n",
              "      (layers): ModuleList(\n",
              "        (0): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=16, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=16, bias=True)\n",
              "          (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (1): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=16, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=16, bias=True)\n",
              "          (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (2): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=16, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=16, bias=True)\n",
              "          (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): TransformerDecoder(\n",
              "      (layers): ModuleList(\n",
              "        (0): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=16, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=16, bias=True)\n",
              "          (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          (dropout3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (1): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=16, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=16, bias=True)\n",
              "          (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          (dropout3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (2): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=16, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=16, bias=True)\n",
              "          (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          (dropout3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (out): Linear(in_features=16, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = Transformer(\n",
        "    model_dim=16, num_heads=2, num_encoder_layers=3, num_decoder_layers=3, dropout_p=0.1\n",
        ").to(device)\n",
        "#model.load_state_dict(torch.load('trained_trans_10_epochs.pth'))\n",
        "model.eval()"
      ],
      "id": "TVMfyWMzlR-C"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kdMbbBnl_Ui",
        "outputId": "5b7526ae-1381-4e34-84d9-12e4c8ea1f1e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTM_Model(\n",
              "  (user_embedding): Embedding(6041, 16)\n",
              "  (movie_embedding): Embedding(3953, 16)\n",
              "  (genre_embedding): Embedding(301, 16)\n",
              "  (sex_embedding): Embedding(2, 16)\n",
              "  (age_embedding): Embedding(60, 16)\n",
              "  (occupation_embedding): Embedding(21, 16)\n",
              "  (lstm): LSTM(16, 32, num_layers=3, batch_first=True, dropout=0.1)\n",
              "  (out): Linear(in_features=32, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "lstm_model = LSTM_Model(\n",
        "    model_dim=16, dropout_p=0.1\n",
        ").to(device)\n",
        "#lstm_model.load_state_dict(torch.load('trained_lstm_10_epochs.pth'))\n",
        "lstm_model.eval()"
      ],
      "id": "2kdMbbBnl_Ui"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mthPslgldxm",
        "outputId": "3d256a9b-ef2e-4230-a585-38cc20b92407"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "val_loss = validation_loop(model, loss_fn, val_dataloader)"
      ],
      "id": "-mthPslgldxm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gmy-UOjzwkun",
        "outputId": "72026e64-991e-4eed-d2c8-0a4e236d2aa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  del sys.path[0]\n"
          ]
        }
      ],
      "source": [
        "l_val_loss = lstm_eval_loop(lstm_model, lstm_loss_fn, val_dataloader)"
      ],
      "id": "Gmy-UOjzwkun"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaVuQvQ0wMUb",
        "outputId": "97809cea-aff8-4dc8-af76-c8c61e0a4dc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy LSTM: 1.354762974015584 TRANS: 1.2122569652482762\n"
          ]
        }
      ],
      "source": [
        "print(\"Accuracy LSTM: {} TRANS: {}\".format(l_val_loss/10, val_loss/10))"
      ],
      "id": "aaVuQvQ0wMUb"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "user item prediction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}